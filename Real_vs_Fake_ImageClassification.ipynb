{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8CvnxbsZ4Az"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "JS6vh3ulZ96W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "metadata": {
        "id": "20b2DUpyaK1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image_Size= 256\n",
        "Batch_Size = 32\n",
        "Channels=3\n",
        "Epochs=50"
      ],
      "metadata": {
        "id": "BKQzHP-uaKrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"../input/real-and-fake-face-detection/real_and_fake_face/\",\n",
        "    shuffle=True,\n",
        "    image_size = (Image_Size,Image_Size),\n",
        "    batch_size=Batch_Size\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "RoUeKNaDaSq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = dataset.class_names\n",
        "class_names"
      ],
      "metadata": {
        "id": "pfpJLfUEaSjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, label_batch in dataset.take(1):\n",
        "    print(image_batch.shape)\n",
        "    print(label_batch.numpy())"
      ],
      "metadata": {
        "id": "wnlTbuA_aXNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, label_batch in dataset.take(1):\n",
        "    plt.imshow(image_batch[0].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[label_batch[0]])"
      ],
      "metadata": {
        "id": "o7XffhEmaZWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def splitting_dataset_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
        "\n",
        "    ds_size=len(ds)\n",
        "\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(shuffle_size, seed=12)\n",
        "\n",
        "    train_size=int(train_split * ds_size)\n",
        "    val_size= int(val_split * ds_size)\n",
        "\n",
        "    train_ds= ds.take(train_size)\n",
        "\n",
        "    val_ds = ds.skip(train_size).take(val_size)\n",
        "    test_ds = ds.skip(train_size).skip(val_size)\n",
        "\n",
        "    return train_ds, val_ds, test_ds"
      ],
      "metadata": {
        "id": "_U_9frVsab9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, val_ds, test_ds=splitting_dataset_tf(dataset)"
      ],
      "metadata": {
        "id": "6dRkEPVpaeJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_ds),len(val_ds),len(test_ds))"
      ],
      "metadata": {
        "id": "dfGjuGfUagKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "2qVyKZAVaiZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resize_and_rescale = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.Resizing(Image_Size,Image_Size),\n",
        "    layers.experimental.preprocessing.Rescaling(1.0/255)\n",
        "])"
      ],
      "metadata": {
        "id": "EE5PaOr4ajV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_aug = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "4WZfOf7MajMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (Batch_Size,Image_Size, Image_Size,Channels)\n",
        "n_classes = 3\n",
        "\n",
        "model = models.Sequential([\n",
        "    resize_and_rescale,\n",
        "    data_aug,\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape = input_shape),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation = 'relu'),\n",
        "    layers.Dense(n_classes, activation= 'softmax'),\n",
        "\n",
        "])\n",
        "\n",
        "model.build(input_shape=input_shape)"
      ],
      "metadata": {
        "id": "HoOqkSk6aq34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "pXWBwHsUatHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=275,\n",
        "    batch_size=Batch_Size,\n",
        "    verbose=1,\n",
        "    validation_data=val_ds\n",
        ")"
      ],
      "metadata": {
        "id": "sKo3SFXSavIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "Oqt959k2ayie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "for image_batch, label_batch in dataset.take(1):\n",
        "\n",
        "    first_image = image_batch[0].numpy().astype('uint8')\n",
        "    first_label = label_batch[0].numpy()\n",
        "\n",
        "    print(\"first image to predict\")\n",
        "    plt.imshow(first_image)\n",
        "    print(\"Actual label : \",class_names[first_label])\n",
        "\n",
        "\n",
        "    batch_pred = model.predict(image_batch)\n",
        "    print(\"Pred label : \",class_names[np.argmax(batch_pred[0])])"
      ],
      "metadata": {
        "id": "VcWa4mtoa00o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred(model, img):\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
        "    img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "\n",
        "    predicted_class = class_names[np.argmax(predictions[0])]\n",
        "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
        "    return predicted_class, confidence"
      ],
      "metadata": {
        "id": "3K5Cba0aa4DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "\n",
        "for images, labels in test_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3,3, i+1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "\n",
        "        predicted_class, confidence = pred(model, images[i].numpy())\n",
        "        actual_class = class_names[labels[i]]\n",
        "\n",
        "        plt.title(f\"Actual : {actual_class},\\n Predicted:{predicted_class}.\\n Confidence:{confidence}%\")\n",
        "\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "tsroIHpda6H0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}